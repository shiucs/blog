<!DOCTYPE html><html lang=zh-CN><head><title>Python 爬虫从入门到放弃（三）Urllib 库的基本使用 - ShiuxのBlog</title><meta charset=UTF-8><meta name=keywords content=""><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=5"><link rel="shortcut icon" href=/logo.svg type=image/x-icon><meta name=description content="什么是 Urllib Urllib 是 python 内置的 HTTP 请求库，包括以下模块  urllib.request - 请求模块 urllib.error - 异常处理模块 urllib.parse - url 解析模块 urllib.robotparser - robots.txt 解析模块  Urllib 基本使用 urlopen 关于 urllib.request.urlopen"><meta property=og:type content=article><meta property=og:title content="Python 爬虫从入门到放弃（三）Urllib 库的基本使用"><meta property=og:url content=https://blog.shiux.com/article/python-spider-3/index.html><meta property=og:site_name content=ShiuxのBlog><meta property=og:description content="什么是 Urllib Urllib 是 python 内置的 HTTP 请求库，包括以下模块  urllib.request - 请求模块 urllib.error - 异常处理模块 urllib.parse - url 解析模块 urllib.robotparser - robots.txt 解析模块  Urllib 基本使用 urlopen 关于 urllib.request.urlopen"><meta property=og:locale content=zh_CN><meta property=og:image content=https://cdn.jsdelivr.net/gh/shiucs/blog@latest/images/9403f483f0a7742c99e2f00d3e87b379.png><meta property=og:image content=https://cdn.jsdelivr.net/gh/shiucs/blog@latest/images/1087ab61706e023b577651442ada2c4a.png><meta property=og:image content=https://cdn.jsdelivr.net/gh/shiucs/blog@latest/images/fefb814a45d52816fab98dc81d672b47.png><meta property=og:image content=https://cdn.jsdelivr.net/gh/shiucs/blog@latest/images/18bf4f402d6c09219fc6e574a3f195f8.png><meta property=og:image content=https://cdn.jsdelivr.net/gh/shiucs/blog@latest/images/71eb3fb011c290339e9ba1f1db60ea77.png><meta property=og:image content=https://cdn.jsdelivr.net/gh/shiucs/blog@latest/images/2ea662510c6b6b6119dcffa5038ed44a.png><meta property=og:image content=https://cdn.jsdelivr.net/gh/shiucs/blog@latest/images/53d7c7f3daf4e17112e1806425372266.png><meta property=article:published_time content=2021-09-04T15:33:05.000Z><meta property=article:modified_time content=2023-01-26T15:50:20.818Z><meta property=article:author content=Shiux><meta property=article:tag content=Spider><meta name=twitter:card content=summary><meta name=twitter:image content=https://cdn.jsdelivr.net/gh/shiucs/blog@latest/images/9403f483f0a7742c99e2f00d3e87b379.png><link rel=stylesheet href=/lib/fancybox/fancybox.css><link rel=stylesheet href=/lib/mdui_043tiny/mdui.css><link rel=stylesheet href="/lib/iconfont/iconfont.css?v=1674748240652"><link rel=stylesheet href="/css/style.css?v=1674748240652"><link rel=stylesheet href="/custom.css?v=1674748240653"><meta name=generator content="Hexo 6.3.0"></head><body class=mdui-drawer-body-left><div id=nexmoe-background><div class=nexmoe-bg style=background-image:url(https://api.ixiaowai.cn/api/api.php)></div><div class="mdui-appbar mdui-shadow-0"><div class=mdui-toolbar><a mdui-drawer="{target: '#drawer', swipe: true}" title=menu class="mdui-btn mdui-btn-icon mdui-ripple"><i class="mdui-icon nexmoefont icon-menu"></i></a><div class=mdui-toolbar-spacer></div><a href=/ title=Shiux class="mdui-btn mdui-btn-icon"><img src=/logo.svg alt=Shiux></a></div></div></div><div id=nexmoe-header><div class="nexmoe-drawer mdui-drawer" id=drawer><div class="nexmoe-avatar mdui-ripple"><a href=/ title=Shiux><img src=/logo.svg alt=Shiux alt=Shiux></a></div><div class=nexmoe-count><div><span>文章</span>47</div><div><span>标签</span>34</div><div><span>分类</span>7</div></div><div class="nexmoe-list mdui-list" mdui-collapse="{accordion: true}"><a class="nexmoe-list-item mdui-list-item mdui-ripple false" href=/ title=回到首页><i class="mdui-list-item-icon nexmoefont icon-home"></i><div class=mdui-list-item-content>回到首页</div></a><a class="nexmoe-list-item mdui-list-item mdui-ripple false" href=/archive.html title=文章归档><i class="mdui-list-item-icon nexmoefont icon-container"></i><div class=mdui-list-item-content>文章归档</div></a><a class="nexmoe-list-item mdui-list-item mdui-ripple false" href=/about.html title=关于博主><i class="mdui-list-item-icon nexmoefont icon-info-circle"></i><div class=mdui-list-item-content>关于博主</div></a></div><aside id=nexmoe-sidebar><div class=nexmoe-widget-wrap><div class="nexmoe-widget nexmoe-social"><a class=mdui-ripple href=https://github.com/shiucs/ target=_blank mdui-tooltip="{content: 'GitHub'}" style=color:#191717;background-color:rgba(25,23,23,.1)><i class="nexmoefont icon-github"></i> </a><a class=mdui-ripple href=https://www.zhihu.com/people/fungyua target=_blank mdui-tooltip="{content: '知乎'}" style=color:#1e88e5;background-color:rgba(30,136,229,.1)><i class="nexmoefont icon-zhihu"></i></a></div></div><div class=nexmoe-widget-wrap><h3 class=nexmoe-widget-title>文章分类</h3><div class=nexmoe-widget><ul class=category-list><li class=category-list-item><a class=category-list-link href=/categories/Code/ >Code</a> <span class=category-list-count>19</span></li><li class=category-list-item><a class=category-list-link href=/categories/Guide/ >Guide</a> <span class=category-list-count>12</span></li><li class=category-list-item><a class=category-list-link href=/categories/Linux/ >Linux</a> <span class=category-list-count>5</span></li><li class=category-list-item><a class=category-list-link href=/categories/MacOS/ >MacOS</a> <span class=category-list-count>5</span></li><li class=category-list-item><a class=category-list-link href=/categories/NetWork/ >NetWork</a> <span class=category-list-count>2</span></li><li class=category-list-item><a class=category-list-link href=/categories/UX/ >UX</a> <span class=category-list-count>1</span></li><li class=category-list-item><a class=category-list-link href=/categories/Windows/ >Windows</a> <span class=category-list-count>3</span></li></ul></div></div><div class=nexmoe-widget-wrap><div id=randomtagcloud class="nexmoe-widget tagcloud nexmoe-rainbow"><a href=/tags/APP/ style=font-size:12.86px>APP</a> <a href=/tags/AdGuard/ style=font-size:11.43px>AdGuard</a> <a href=/tags/Aria2/ style=font-size:10px>Aria2</a> <a href=/tags/CentOS/ style=font-size:12.86px>CentOS</a> <a href=/tags/Cloud/ style=font-size:10px>Cloud</a> <a href=/tags/DNS/ style=font-size:10px>DNS</a> <a href=/tags/Docker/ style=font-size:11.43px>Docker</a> <a href=/tags/Git/ style=font-size:11.43px>Git</a> <a href=/tags/HTML/ style=font-size:11.43px>HTML</a> <a href=/tags/Hackintosh/ style=font-size:11.43px>Hackintosh</a> <a href=/tags/Hexo/ style=font-size:11.43px>Hexo</a> <a href=/tags/IP/ style=font-size:11.43px>IP</a> <a href=/tags/Issue/ style=font-size:11.43px>Issue</a> <a href=/tags/JavaScript/ style=font-size:14.29px>JavaScript</a> <a href=/tags/JetBrains/ style=font-size:10px>JetBrains</a> <a href=/tags/Linux/ style=font-size:10px>Linux</a> <a href=/tags/MacOS/ style=font-size:10px>MacOS</a> <a href=/tags/MySQL/ style=font-size:11.43px>MySQL</a> <a href=/tags/NGINX/ style=font-size:10px>NGINX</a> <a href=/tags/NextCloud/ style=font-size:11.43px>NextCloud</a> <a href=/tags/Nodejs/ style=font-size:14.29px>Nodejs</a> <a href=/tags/PHP/ style=font-size:12.86px>PHP</a> <a href=/tags/SSH/ style=font-size:10px>SSH</a> <a href=/tags/Spider/ style=font-size:17.14px>Spider</a> <a href=/tags/Ubuntu/ style=font-size:11.43px>Ubuntu</a> <a href=/tags/npm/ style=font-size:11.43px>npm</a> <a href=/tags/Code/ style=font-size:12.86px>代码</a> <a href=/tags/FrontEnd/ style=font-size:11.43px>前端</a> <a href=/tags/Consult/ style=font-size:15.71px>咨询</a> <a href=/tags/Skill/ style=font-size:20px>技巧</a> <a href=/tags/Note/ style=font-size:18.57px>笔记</a> <a href=/tags/Terminal/ style=font-size:12.86px>终端</a> <a href=/tags/DSM/ style=font-size:10px>群晖</a> <a href=/tags/Sources/ style=font-size:10px>软件源</a></div><script>for(var maxTagcloud=parseInt(17),tags_length=parseInt(34),tags_arr=[],i=0;i<tags_length;i++)tags_arr.push(i);tags_arr.sort(function(a,t){return.5<Math.random()?-1:1});for(var tags_arr=tags_arr.slice(0,maxTagcloud<tags_length?tags_length-maxTagcloud:0),tag_i=0;tag_i<tags_arr.length;tag_i++)document.getElementById("randomtagcloud").children[tags_arr[tag_i]].style.display="none"</script></div><div class=nexmoe-widget-wrap><h3 class=nexmoe-widget-title>一言</h3><div class=nexmoe-widget><ul class=hitokoto-box><li id=hitokoto_text_parent class=hitokoto-text hitokotocategory=""><a href=# id=hitokoto_text></a> <a href=# id=hitokoto_error_text style=display:none></a></li></ul></div></div><script>let hitokotoText=document.getElementById("hitokoto_text"),hitokotoErroText=document.getElementById("hitokoto_error_text"),hitokotoCategory=document.getElementById("hitokoto_text_parent").getAttribute("hitokotoCategory");window.onload=function(){let t="https://v1.hitokoto.cn";hitokotoCategory&&(t+="?c="+hitokotoCategory),fetch(t).then(t=>t.json()).then(t=>{hitokotoText.innerText="「 "+t.hitokoto+" 」 from "+t.from,hitokotoText.href="https://hitokoto.cn/?uuid="+t.uuid}).catch(t=>{console.error(11,t),hitokotoText.style.display="none",hitokotoErroText.style.display="block"})}</script><div class=nexmoe-widget-wrap><h3 class=nexmoe-widget-title>文章归档</h3><div class=nexmoe-widget><ul class=archive-list><li class=archive-list-item><a class=archive-list-link href=/archives/2023/ >2023</a><span class=archive-list-count>6</span></li><li class=archive-list-item><a class=archive-list-link href=/archives/2022/ >2022</a><span class=archive-list-count>2</span></li><li class=archive-list-item><a class=archive-list-link href=/archives/2021/ >2021</a><span class=archive-list-count>18</span></li><li class=archive-list-item><a class=archive-list-link href=/archives/2020/ >2020</a><span class=archive-list-count>20</span></li><li class=archive-list-item><a class=archive-list-link href=/archives/2019/ >2019</a><span class=archive-list-count>1</span></li></ul></div></div><div class=nexmoe-widget-wrap><h3 class=nexmoe-widget-title>最新文章</h3><div class=nexmoe-widget><ul><li><a href=/article/hackintosh-one-key-hidip/ >黑苹果一键 HiDPI</a></li><li><a href=/article/say-no-to-meta-keywords/ >Meta Keywords：是什么、为什么不</a></li><li><a href=/article/dsm7-x-boot-compilation/ >黑群晖 DSM7.X 引导编译</a></li><li><a href=/article/lang-tag/ >HTML 设置 lang 属性的意义</a></li><li><a href=/article/hackintosh-sleep-issue/ >黑苹果合盖睡眠问题修复</a></li></ul></div></div></aside><div class=nexmoe-copyright>&copy; 2023 Shiux Powered by <a href=http://hexo.io/ target=_blank>Hexo</a> & <a href=https://github.com/theme-nexmoe/hexo-theme-nexmoe target=_blank>Nexmoe</a></div></div></div><div id=nexmoe-content><div class=nexmoe-primary><div class=nexmoe-post><article><div class=nexmoe-post-cover><img src=https://api.ixiaowai.cn/api/api.php alt="Python 爬虫从入门到放弃（三）Urllib 库的基本使用" loading=lazy><h1>Python 爬虫从入门到放弃（三）Urllib 库的基本使用</h1></div><div class=nexmoe-post-meta><div class=nexmoe-rainbow><a class="nexmoefont icon-calendar-fill">2021年09月04日</a> <a class="nexmoefont icon-appstore-fill -link" href=/categories/Code/ >Code</a> <a><i class="nexmoefont icon-areachart"></i>约2.1k字</a> <a><i class="nexmoefont icon-time-circle-fill"></i>预计需要9分钟</a></div></div><h2 id=什么是Urllib>什么是 Urllib</h2><p>Urllib 是 python 内置的 HTTP 请求库，包括以下模块</p><ul><li><code>urllib.request</code> - 请求模块</li><li><code>urllib.error</code> - 异常处理模块</li><li><code>urllib.parse</code> - url 解析模块</li><li><code>urllib.robotparser</code> - robots.txt 解析模块</li></ul><h2 id=Urllib基本使用>Urllib 基本使用</h2><h3 id=urlopen>urlopen</h3><p>关于 <code>urllib.request.urlopen</code> 参数的介绍：</p><figure class="highlight python"><table><tbody><tr><td class=gutter><pre><span class=line>1</span><br></pre></td><td class=code><pre><code class="hljs python">urllib.request.urlopen(url, data=<span class=hljs-literal>None</span>, [timeout, ]*, cafile=<span class=hljs-literal>None</span>, capath=<span class=hljs-literal>None</span>, cadefault=<span class=hljs-literal>False</span>, context=<span class=hljs-literal>None</span>)<br></code></pre></td></tr></tbody></table></figure><ul><li>url：url 地址。</li><li>data：发送到服务器的其他数据对象，默认为 None。</li><li>timeout：设置访问超时时间。</li><li>cafile 和 capath：cafile 为 CA 证书， capath 为 CA 证书的路径，使用 HTTPS 需要用到。</li><li>cadefault：已经被弃用。</li><li>context：ssl.SSLContext 类型，用来指定 SSL 设置。</li></ul><h4 id=url参数的使用>url 参数的使用</h4><p>先写一个简单的例子：</p><figure class="highlight python"><table><tbody><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br></pre></td><td class=code><pre><code class="hljs python"><span class=hljs-keyword>import</span> urllib.request<br><br>response = urllib.request.urlopen(<span class=hljs-string>'https://www.baidu.com'</span>)<br><span class=hljs-built_in>print</span>(response.read().decode(<span class=hljs-string>'utf-8'</span>))<br></code></pre></td></tr></tbody></table></figure><p><code>response.read()</code> 可以获取到网页的内容，如果没有 <code>read()</code>，将返回如下内容</p><p><code>&lt;http.client.HTTPResponse object at 0x00000215D37663A0&gt;</code></p><h4 id=data参数的使用>data 参数的使用</h4><p>上述的例子是通过 get 请求获得请求内容，下面使用 urllib 的 post 请求</p><p>这里通过 <a target=_blank rel=noopener href=http://httpbin.org/post>http://httpbin.org/post</a> 演示（该网站可以作为练习使用 urllib 的一个站点使用，可以<br>模拟各种请求操作）。</p><figure class="highlight python"><table><tbody><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br></pre></td><td class=code><pre><code class="hljs python"><span class=hljs-keyword>import</span> urllib.parse<br><span class=hljs-keyword>import</span> urllib.request<br><br>data = <span class=hljs-built_in>bytes</span>(urllib.parse.urlencode({<span class=hljs-string>'word'</span>: <span class=hljs-string>'hello'</span>}), encoding=<span class=hljs-string>'utf8'</span>)<br><span class=hljs-built_in>print</span>(data)<br>response = urllib.request.urlopen(<span class=hljs-string>'http://httpbin.org/post'</span>, data=data)<br><span class=hljs-built_in>print</span>(response.read())<br></code></pre></td></tr></tbody></table></figure><p>这里就用到 <code>urllib.parse</code>，通过 <code>bytes(urllib.parse.urlencode())</code> 可以将 post 数据进行转换放到 <code>urllib.request.urlopen</code> 的 <code>data</code> 参数中。这样就完成了一次 post 请求。</p><p>所以如果我们添加 <code>data</code> 参数的时候就是以 post 请求方式请求，如果没有 data 参数就是 get 请求方式</p><h4 id=timeout参数的使用>timeout 参数的使用</h4><p>在某些网络情况不好或者服务器端异常的情况会出现请求慢的情况，或者请求异常，所以这个时候我们需要给请求设置一个超时时间，而不是让程序一直在等待结果。例子如下：</p><figure class="highlight python"><table><tbody><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br></pre></td><td class=code><pre><code class="hljs python"><span class=hljs-keyword>import</span> urllib.request<br><br>response = urllib.request.urlopen(<span class=hljs-string>'http://httpbin.org/get'</span>, timeout=<span class=hljs-number>1</span>)<br><span class=hljs-built_in>print</span>(response.read())<br></code></pre></td></tr></tbody></table></figure><p>运行之后我们看到可以正常的返回结果，接着我们将 timeout 时间设置为 0.1，运行程序会提示如下错误：</p><p><img onerror=imgOnError(this) data-fancybox=gallery src=https://cdn.jsdelivr.net/gh/shiucs/blog@latest/images/9403f483f0a7742c99e2f00d3e87b379.png alt="" data-caption="" loading=lazy></p><p>所以我们需要对异常进行抓取，代码更改为</p><figure class="highlight python"><table><tbody><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br></pre></td><td class=code><pre><code class="hljs python"><span class=hljs-keyword>import</span> socket<br><span class=hljs-keyword>import</span> urllib.request<br><span class=hljs-keyword>import</span> urllib.error<br><br><span class=hljs-keyword>try</span>:<br>    response = urllib.request.urlopen(<span class=hljs-string>'http://httpbin.org/get'</span>, timeout=<span class=hljs-number>0.1</span>)<br><span class=hljs-keyword>except</span> urllib.error.URLError <span class=hljs-keyword>as</span> e:<br>    <span class=hljs-keyword>if</span> <span class=hljs-built_in>isinstance</span>(e.reason, socket.timeout):<br>        <span class=hljs-built_in>print</span>(<span class=hljs-string>'TIME OUT'</span>)<br></code></pre></td></tr></tbody></table></figure><p>这样超时时返回以下内容：</p><p><img onerror=imgOnError(this) data-fancybox=gallery src=https://cdn.jsdelivr.net/gh/shiucs/blog@latest/images/1087ab61706e023b577651442ada2c4a.png alt="" data-caption="" loading=lazy></p><h4 id=响应>响应</h4><h5 id=响应类型、状态码、响应头>响应类型、状态码、响应头</h5><figure class="highlight python"><table><tbody><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br></pre></td><td class=code><pre><code class="hljs python"><span class=hljs-keyword>import</span> urllib.request<br><br>response = urllib.request.urlopen(<span class=hljs-string>'https://www.python.org'</span>)<br><span class=hljs-built_in>print</span>(<span class=hljs-built_in>type</span>(response))<br></code></pre></td></tr></tbody></table></figure><p>可以看到结果为：</p><p><img onerror=imgOnError(this) data-fancybox=gallery src=https://cdn.jsdelivr.net/gh/shiucs/blog@latest/images/fefb814a45d52816fab98dc81d672b47.png alt="" data-caption="" loading=lazy></p><p>我们可以通过 <code>response.status</code>、<code>response.getheaders()</code>，获取状态码以及头部信息</p><p><code>response.read()</code> 获得的是响应体的内容</p><p>当然上述的 <code>urlopen</code> 只能用于一些简单的请求，因为它无法添加一些 header 信息，如果后面写爬虫我们可以知道，很多情况下我们是需要添加头部信息去访问目标站的，这个时候就用到了 urllib.request</p><h3 id=request>request</h3><h4 id=设置Headers>设置 Headers</h4><p>有很多网站为了防止程序爬虫爬网站造成网站瘫痪，会需要携带一些 headers 头部信息才能访问，最长见的有 <code>user-agent</code> 参数</p><p>写一个简单的例子：</p><figure class="highlight python"><table><tbody><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br></pre></td><td class=code><pre><code class="hljs python"><span class=hljs-keyword>import</span> urllib.request<br><br>request = urllib.request.Request(<span class=hljs-string>'https://python.org'</span>)<br>response = urllib.request.urlopen(request)<br><span class=hljs-built_in>print</span>(response.read().decode(<span class=hljs-string>'utf-8'</span>))<br></code></pre></td></tr></tbody></table></figure><p>给请求添加头部信息，从而定制自己请求网站是时的头部信息</p><figure class="highlight python"><table><tbody><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br><span class=line>10</span><br><span class=line>11</span><br><span class=line>12</span><br><span class=line>13</span><br><span class=line>14</span><br></pre></td><td class=code><pre><code class="hljs python"><span class=hljs-keyword>from</span> urllib <span class=hljs-keyword>import</span> request, parse<br><br>url = <span class=hljs-string>'http://httpbin.org/post'</span><br>headers = {<br>    <span class=hljs-string>'User-Agent'</span>: <span class=hljs-string>'Mozilla/4.0 (compatible; MSIE 5.5; Windows NT)'</span>,<br>    <span class=hljs-string>'Host'</span>: <span class=hljs-string>'httpbin.org'</span><br>}<br><span class=hljs-built_in>dict</span> = {<br>    <span class=hljs-string>'name'</span>: <span class=hljs-string>'zhaofan'</span><br>}<br>data = <span class=hljs-built_in>bytes</span>(parse.urlencode(<span class=hljs-built_in>dict</span>), encoding=<span class=hljs-string>'utf8'</span>)<br>req = request.Request(url=url, data=data, headers=headers, method=<span class=hljs-string>'POST'</span>)<br>response = request.urlopen(req)<br><span class=hljs-built_in>print</span>(response.read().decode(<span class=hljs-string>'utf-8'</span>))<br></code></pre></td></tr></tbody></table></figure><p>添加请求头的第二种方式</p><figure class="highlight python"><table><tbody><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br><span class=line>10</span><br><span class=line>11</span><br></pre></td><td class=code><pre><code class="hljs python"><span class=hljs-keyword>from</span> urllib <span class=hljs-keyword>import</span> request, parse<br><br>url = <span class=hljs-string>'http://httpbin.org/post'</span><br><span class=hljs-built_in>dict</span> = {<br>    <span class=hljs-string>'name'</span>: <span class=hljs-string>'Germey'</span><br>}<br>data = <span class=hljs-built_in>bytes</span>(parse.urlencode(<span class=hljs-built_in>dict</span>), encoding=<span class=hljs-string>'utf8'</span>)<br>req = request.Request(url=url, data=data, method=<span class=hljs-string>'POST'</span>)<br>req.add_header(<span class=hljs-string>'User-Agent'</span>, <span class=hljs-string>'Mozilla/4.0 (compatible; MSIE 5.5; Windows NT)'</span>)<br>response = request.urlopen(req)<br><span class=hljs-built_in>print</span>(response.read().decode(<span class=hljs-string>'utf-8'</span>))<br></code></pre></td></tr></tbody></table></figure><p>这种添加方式有个好处是自己可以定义一个请求头字典，然后循环进行添加</p><h4 id=高级用法各种handler>高级用法各种 handler</h4><h5 id=代理-ProxyHandler>代理，ProxyHandler</h5><p>通过 <code>urllib.request.ProxyHandler()</code> 可以设置代理，网站它会检测某一段时间某个 IP 的访问次数，如果访问次数过多，它会禁止你的访问，所以这个时候需要通过设置代理来爬取数据</p><figure class="highlight python"><table><tbody><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br></pre></td><td class=code><pre><code class="hljs python"><span class=hljs-keyword>import</span> urllib.request<br><br>proxy_handler = urllib.request.ProxyHandler({<br>    <span class=hljs-string>'http'</span>: <span class=hljs-string>'http://127.0.0.1:9743'</span>,<br>    <span class=hljs-string>'https'</span>: <span class=hljs-string>'https://127.0.0.1:9743'</span><br>})<br>opener = urllib.request.build_opener(proxy_handler)<br>response = opener.<span class=hljs-built_in>open</span>(<span class=hljs-string>'http://httpbin.org/get'</span>)<br><span class=hljs-built_in>print</span>(response.read())<br></code></pre></td></tr></tbody></table></figure><h5 id=cookie-HTTPCookiProcessor>cookie,HTTPCookiProcessor</h5><p>cookie 中保存中我们常见的登录信息，有时候爬取网站需要携带 cookie 信息访问，这里用到了 <code>http.cookiejar</code>，用于获取 cookie 以及存储 cookie</p><figure class="highlight python"><table><tbody><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br></pre></td><td class=code><pre><code class="hljs python"><span class=hljs-keyword>import</span> http.cookiejar, urllib.request<br>cookie = http.cookiejar.CookieJar()<br>handler = urllib.request.HTTPCookieProcessor(cookie)<br>opener = urllib.request.build_opener(handler)<br>response = opener.<span class=hljs-built_in>open</span>(<span class=hljs-string>'http://www.baidu.com'</span>)<br><span class=hljs-keyword>for</span> item <span class=hljs-keyword>in</span> cookie:<br>    <span class=hljs-built_in>print</span>(item.name+<span class=hljs-string>"="</span>+item.value)<br></code></pre></td></tr></tbody></table></figure><p>同时 cookie 可以写入到文件中保存，有两种方式 <code>http.cookiejar.MozillaCookieJar</code> 和 <code>http.cookiejar.LWPCookieJar()</code>，当然你自己用哪种方式都可以</p><p>具体代码例子如下：</p><figure class="highlight python"><table><tbody><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br><span class=line>10</span><br><span class=line>11</span><br><span class=line>12</span><br><span class=line>13</span><br><span class=line>14</span><br><span class=line>15</span><br><span class=line>16</span><br><span class=line>17</span><br></pre></td><td class=code><pre><code class="hljs python"><span class=hljs-comment># http.cookiejar.MozillaCookieJar()</span><br><span class=hljs-keyword>import</span> http.cookiejar, urllib.request<br>filename = <span class=hljs-string>"cookie.txt"</span><br>cookie = http.cookiejar.MozillaCookieJar(filename)<br>handler = urllib.request.HTTPCookieProcessor(cookie)<br>opener = urllib.request.build_opener(handler)<br>response = opener.<span class=hljs-built_in>open</span>(<span class=hljs-string>'http://www.baidu.com'</span>)<br>cookie.save(ignore_discard=<span class=hljs-literal>True</span>, ignore_expires=<span class=hljs-literal>True</span>)<br><br><span class=hljs-comment># http.cookiejar.LWPCookieJar()</span><br><span class=hljs-keyword>import</span> http.cookiejar, urllib.request<br>filename = <span class=hljs-string>'cookie.txt'</span><br>cookie = http.cookiejar.LWPCookieJar(filename)<br>handler = urllib.request.HTTPCookieProcessor(cookie)<br>opener = urllib.request.build_opener(handler)<br>response = opener.<span class=hljs-built_in>open</span>(<span class=hljs-string>'http://www.baidu.com'</span>)<br>cookie.save(ignore_discard=<span class=hljs-literal>True</span>, ignore_expires=<span class=hljs-literal>True</span>)<br></code></pre></td></tr></tbody></table></figure><p>同样的如果想要通过获取文件中的 cookie 获取的话可以通过 load 方式，当然用哪种方式写入的，就用哪种方式读取。</p><figure class="highlight python"><table><tbody><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br></pre></td><td class=code><pre><code class="hljs python"><br><span class=hljs-keyword>import</span> http.cookiejar, urllib.request<br>cookie = http.cookiejar.LWPCookieJar()<br>cookie.load(<span class=hljs-string>'cookie.txt'</span>, ignore_discard=<span class=hljs-literal>True</span>, ignore_expires=<span class=hljs-literal>True</span>)<br>handler = urllib.request.HTTPCookieProcessor(cookie)<br>opener = urllib.request.build_opener(handler)<br>response = opener.<span class=hljs-built_in>open</span>(<span class=hljs-string>'http://www.baidu.com'</span>)<br><span class=hljs-built_in>print</span>(response.read().decode(<span class=hljs-string>'utf-8'</span>))<br></code></pre></td></tr></tbody></table></figure><h3 id=异常处理>异常处理</h3><p>在很多时候我们通过程序访问页面的时候，有的页面可能会出现错误，类似 404，500 等错误</p><p>这个时候就需要我们捕捉异常，下面先写一个简单的例子</p><figure class="highlight python"><table><tbody><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br></pre></td><td class=code><pre><code class="hljs python"><span class=hljs-keyword>from</span> urllib <span class=hljs-keyword>import</span> request,error<br><br><span class=hljs-keyword>try</span>:<br>    response = request.urlopen(<span class=hljs-string>"http://pythonsite.com/1111.html"</span>)<br><span class=hljs-keyword>except</span> error.URLError <span class=hljs-keyword>as</span> e:<br>    <span class=hljs-built_in>print</span>(e.reason)<br></code></pre></td></tr></tbody></table></figure><p>上述代码访问的是一个不存在的页面，通过捕捉异常，我们可以打印异常错误</p><p>这里我们需要知道的是在 urllb 异常这里有两个异常错误：</p><p><code>URLError</code>，<code>HTTPError</code> —— <code>HTTPError</code> 是 <code>URLError</code> 的子类</p><p><code>URLError</code> 里只有一个属性：<code>reason</code>，即抓异常的时候只能打印错误信息，类似上面的例子</p><p><code>HTTPError</code> 里有三个属性：<code>code</code>,<code>reason</code>,<code>headers</code>，即抓异常的时候可以获得 <code>code</code>，<code>reason</code>，<code>headers</code> 三个信息，例子如下：</p><figure class="highlight python"><table><tbody><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br><span class=line>10</span><br><span class=line>11</span><br><span class=line>12</span><br></pre></td><td class=code><pre><code class="hljs python"><span class=hljs-keyword>from</span> urllib <span class=hljs-keyword>import</span> request,error<br><span class=hljs-keyword>try</span>:<br>    response = request.urlopen(<span class=hljs-string>"http://pythonsite.com/1111.html"</span>)<br><span class=hljs-keyword>except</span> error.HTTPError <span class=hljs-keyword>as</span> e:<br>    <span class=hljs-built_in>print</span>(e.reason)<br>    <span class=hljs-built_in>print</span>(e.code)<br>    <span class=hljs-built_in>print</span>(e.headers)<br><span class=hljs-keyword>except</span> error.URLError <span class=hljs-keyword>as</span> e:<br>    <span class=hljs-built_in>print</span>(e.reason)<br><br><span class=hljs-keyword>else</span>:<br>    <span class=hljs-built_in>print</span>(<span class=hljs-string>"reqeust successfully"</span>)<br></code></pre></td></tr></tbody></table></figure><p>同时，e.reason 其实也可以在做深入的判断，例子如下：</p><figure class="highlight python"><table><tbody><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br><span class=line>10</span><br></pre></td><td class=code><pre><code class="hljs python"><span class=hljs-keyword>import</span> socket<br><br><span class=hljs-keyword>from</span> urllib <span class=hljs-keyword>import</span> error,request<br><br><span class=hljs-keyword>try</span>:<br>    response = request.urlopen(<span class=hljs-string>"http://www.pythonsite.com/"</span>,timeout=<span class=hljs-number>0.001</span>)<br><span class=hljs-keyword>except</span> error.URLError <span class=hljs-keyword>as</span> e:<br>    <span class=hljs-built_in>print</span>(<span class=hljs-built_in>type</span>(e.reason))<br>    <span class=hljs-keyword>if</span> <span class=hljs-built_in>isinstance</span>(e.reason,socket.timeout):<br>        <span class=hljs-built_in>print</span>(<span class=hljs-string>"time out"</span>)<br></code></pre></td></tr></tbody></table></figure><h3 id=URL解析>URL 解析</h3><h4 id=urlparse>urlparse</h4><p>URL 解析函数的重点是将 URL 字符串拆分为其组件，或者将 URL 组件组合为 URL 字符串。</p><figure class="highlight python"><table><tbody><tr><td class=gutter><pre><span class=line>1</span><br></pre></td><td class=code><pre><code class="hljs python">urllib.parse.urlparse(urlstring, scheme=<span class=hljs-string>''</span>, allow_fragments=<span class=hljs-literal>True</span>)<br></code></pre></td></tr></tbody></table></figure><p>功能一：</p><figure class="highlight python"><table><tbody><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br></pre></td><td class=code><pre><code class="hljs python"><span class=hljs-keyword>from</span> urllib.parse <span class=hljs-keyword>import</span> urlparse<br><br>result = urlparse(<span class=hljs-string>"http://www.baidu.com/index.html;user?id=5#comment"</span>)<br><span class=hljs-built_in>print</span>(result)<br></code></pre></td></tr></tbody></table></figure><p>输出：</p><p><img onerror=imgOnError(this) data-fancybox=gallery src=https://cdn.jsdelivr.net/gh/shiucs/blog@latest/images/18bf4f402d6c09219fc6e574a3f195f8.png alt="" data-caption="" loading=lazy></p><p>这里就是可以对你传入的 url 地址进行拆分</p><p>同时我们是可以指定协议类型：</p><p><code>result = urlparse("www.baidu.com/index.html;user?id=5#comment",scheme="https")</code></p><p>这样拆分的时候协议类型部分就会是你指定的部分，当然如果你的 url 里面已经带了协议，你再通过 scheme 指定的协议就不会生效</p><h4 id=urlunpars>urlunpars</h4><p>其实功能和 urlparse 的功能相反，它是用于拼接，例子如下：</p><figure class="highlight python"><table><tbody><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br></pre></td><td class=code><pre><code class="hljs python"><span class=hljs-keyword>from</span> urllib.parse <span class=hljs-keyword>import</span> urlunparse<br><br>data = [<span class=hljs-string>'http'</span>,<span class=hljs-string>'www.baidu.com'</span>,<span class=hljs-string>'index.html'</span>,<span class=hljs-string>'user'</span>,<span class=hljs-string>'a=123'</span>,<span class=hljs-string>'commit'</span>]<br><span class=hljs-built_in>print</span>(urlunparse(data))<br></code></pre></td></tr></tbody></table></figure><p>输出：</p><p><img onerror=imgOnError(this) data-fancybox=gallery src=https://cdn.jsdelivr.net/gh/shiucs/blog@latest/images/71eb3fb011c290339e9ba1f1db60ea77.png alt="" data-caption="" loading=lazy></p><h4 id=urljoin>urljoin</h4><p>这个的功能其实是做拼接的，例子如下：</p><figure class="highlight python"><table><tbody><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br><span class=line>10</span><br></pre></td><td class=code><pre><code class="hljs python"><span class=hljs-keyword>from</span> urllib.parse <span class=hljs-keyword>import</span> urljoin<br><br><span class=hljs-built_in>print</span>(urljoin(<span class=hljs-string>'http://www.baidu.com'</span>, <span class=hljs-string>'FAQ.html'</span>))<br><span class=hljs-built_in>print</span>(urljoin(<span class=hljs-string>'http://www.baidu.com'</span>, <span class=hljs-string>'https://pythonsite.com/FAQ.html'</span>))<br><span class=hljs-built_in>print</span>(urljoin(<span class=hljs-string>'http://www.baidu.com/about.html'</span>, <span class=hljs-string>'https://pythonsite.com/FAQ.html'</span>))<br><span class=hljs-built_in>print</span>(urljoin(<span class=hljs-string>'http://www.baidu.com/about.html'</span>, <span class=hljs-string>'https://pythonsite.com/FAQ.html?question=2'</span>))<br><span class=hljs-built_in>print</span>(urljoin(<span class=hljs-string>'http://www.baidu.com?wd=abc'</span>, <span class=hljs-string>'https://pythonsite.com/index.php'</span>))<br><span class=hljs-built_in>print</span>(urljoin(<span class=hljs-string>'http://www.baidu.com'</span>, <span class=hljs-string>'?category=2#comment'</span>))<br><span class=hljs-built_in>print</span>(urljoin(<span class=hljs-string>'www.baidu.com'</span>, <span class=hljs-string>'?category=2#comment'</span>))<br><span class=hljs-built_in>print</span>(urljoin(<span class=hljs-string>'www.baidu.com#comment'</span>, <span class=hljs-string>'?category=2'</span>))<br></code></pre></td></tr></tbody></table></figure><p>输出：</p><p><img onerror=imgOnError(this) data-fancybox=gallery src=https://cdn.jsdelivr.net/gh/shiucs/blog@latest/images/2ea662510c6b6b6119dcffa5038ed44a.png alt="" data-caption="" loading=lazy></p><p>从拼接的结果我们可以看出，拼接的时候后面的优先级高于前面的 url</p><h4 id=urlencode>urlencode</h4><p>这个方法可以将字典转换为 url 参数，例子如下</p><figure class="highlight python"><table><tbody><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br><span class=line>10</span><br></pre></td><td class=code><pre><code class="hljs python"><span class=hljs-keyword>from</span> urllib.parse <span class=hljs-keyword>import</span> urlencode<br><br>params = {<br>    <span class=hljs-string>"name"</span>:<span class=hljs-string>"zhaofan"</span>,<br>    <span class=hljs-string>"age"</span>:<span class=hljs-number>23</span>,<br>}<br>base_url = <span class=hljs-string>"http://www.baidu.com?"</span><br><br>url = base_url+urlencode(params)<br><span class=hljs-built_in>print</span>(url)<br></code></pre></td></tr></tbody></table></figure><p>输出：</p><p><img onerror=imgOnError(this) data-fancybox=gallery src=https://cdn.jsdelivr.net/gh/shiucs/blog@latest/images/53d7c7f3daf4e17112e1806425372266.png alt="" data-caption="" loading=lazy></p><h2 id=最后>最后</h2><p>这里只是简单介绍基本操作，高级操作请 look 官方文档。</p><p><strong>官方文档</strong> - <a target=_blank rel=noopener href=https://docs.python.org/3/library/urllib.html>https://docs.python.org/3/library/urllib.html</a></p></article><div class=nexmoe-post-copyright><strong>本文作者：</strong>Shiux<br><strong>本文链接：</strong><a href=https://blog.shiux.com/article/python-spider-3/ title=https:&#x2F;&#x2F;blog.shiux.com&#x2F;article&#x2F;python-spider-3&#x2F; target=_blank rel=noopener>https:&#x2F;&#x2F;blog.shiux.com&#x2F;article&#x2F;python-spider-3&#x2F;</a><br><strong>版权声明：</strong>本文采用 <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/cn/deed.zh target=_blank>CC BY-NC-SA 3.0 CN</a> 协议进行许可</div><div class="nexmoe-post-meta nexmoe-rainbow"><a class="nexmoefont icon-tag-fill -none-link" href=/tags/Spider/ rel=tag>Spider</a></div><div class=nexmoe-post-footer><script src=https://giscus.app/client.js data-repo=fungyua/blog-comments data-repo-id="MDEwOlJlcG9zaXRvcnk0MDQ0NTY2OTQ=" data-category=Comments data-category-id=DIC_kwDOGBuE9s4CTUfb data-mapping=pathname data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=bottom data-theme=light data-lang=zh-CN crossorigin=anonymous async></script></div></div><div class=nexmoe-post-right><div class=nexmoe-fixed><div class=nexmoe-tool><button class="mdui-fab catalog" style=overflow:unset><i class="nexmoefont icon-i-catalog"></i><div class=nexmoe-toc><ol class=toc><li class="toc-item toc-level-2"><a class=toc-link href=#%E4%BB%80%E4%B9%88%E6%98%AFUrllib><span class=toc-number>1.</span> <span class=toc-text>什么是 Urllib</span></a></li><li class="toc-item toc-level-2"><a class=toc-link href=#Urllib%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8><span class=toc-number>2.</span> <span class=toc-text>Urllib 基本使用</span></a><ol class=toc-child><li class="toc-item toc-level-3"><a class=toc-link href=#urlopen><span class=toc-number>2.1.</span> <span class=toc-text>urlopen</span></a><ol class=toc-child><li class="toc-item toc-level-4"><a class=toc-link href=#url%E5%8F%82%E6%95%B0%E7%9A%84%E4%BD%BF%E7%94%A8><span class=toc-number>2.1.1.</span> <span class=toc-text>url 参数的使用</span></a></li><li class="toc-item toc-level-4"><a class=toc-link href=#data%E5%8F%82%E6%95%B0%E7%9A%84%E4%BD%BF%E7%94%A8><span class=toc-number>2.1.2.</span> <span class=toc-text>data 参数的使用</span></a></li><li class="toc-item toc-level-4"><a class=toc-link href=#timeout%E5%8F%82%E6%95%B0%E7%9A%84%E4%BD%BF%E7%94%A8><span class=toc-number>2.1.3.</span> <span class=toc-text>timeout 参数的使用</span></a></li><li class="toc-item toc-level-4"><a class=toc-link href=#%E5%93%8D%E5%BA%94><span class=toc-number>2.1.4.</span> <span class=toc-text>响应</span></a><ol class=toc-child><li class="toc-item toc-level-5"><a class=toc-link href=#%E5%93%8D%E5%BA%94%E7%B1%BB%E5%9E%8B%E3%80%81%E7%8A%B6%E6%80%81%E7%A0%81%E3%80%81%E5%93%8D%E5%BA%94%E5%A4%B4><span class=toc-number>2.1.4.1.</span> <span class=toc-text>响应类型、状态码、响应头</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class=toc-link href=#request><span class=toc-number>2.2.</span> <span class=toc-text>request</span></a><ol class=toc-child><li class="toc-item toc-level-4"><a class=toc-link href=#%E8%AE%BE%E7%BD%AEHeaders><span class=toc-number>2.2.1.</span> <span class=toc-text>设置 Headers</span></a></li><li class="toc-item toc-level-4"><a class=toc-link href=#%E9%AB%98%E7%BA%A7%E7%94%A8%E6%B3%95%E5%90%84%E7%A7%8Dhandler><span class=toc-number>2.2.2.</span> <span class=toc-text>高级用法各种 handler</span></a><ol class=toc-child><li class="toc-item toc-level-5"><a class=toc-link href=#%E4%BB%A3%E7%90%86-ProxyHandler><span class=toc-number>2.2.2.1.</span> <span class=toc-text>代理，ProxyHandler</span></a></li><li class="toc-item toc-level-5"><a class=toc-link href=#cookie-HTTPCookiProcessor><span class=toc-number>2.2.2.2.</span> <span class=toc-text>cookie,HTTPCookiProcessor</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class=toc-link href=#%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86><span class=toc-number>2.3.</span> <span class=toc-text>异常处理</span></a></li><li class="toc-item toc-level-3"><a class=toc-link href=#URL%E8%A7%A3%E6%9E%90><span class=toc-number>2.4.</span> <span class=toc-text>URL 解析</span></a><ol class=toc-child><li class="toc-item toc-level-4"><a class=toc-link href=#urlparse><span class=toc-number>2.4.1.</span> <span class=toc-text>urlparse</span></a></li><li class="toc-item toc-level-4"><a class=toc-link href=#urlunpars><span class=toc-number>2.4.2.</span> <span class=toc-text>urlunpars</span></a></li><li class="toc-item toc-level-4"><a class=toc-link href=#urljoin><span class=toc-number>2.4.3.</span> <span class=toc-text>urljoin</span></a></li><li class="toc-item toc-level-4"><a class=toc-link href=#urlencode><span class=toc-number>2.4.4.</span> <span class=toc-text>urlencode</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class=toc-link href=#%E6%9C%80%E5%90%8E><span class=toc-number>3.</span> <span class=toc-text>最后</span></a></li></ol></div></button> <a href=#nexmoe-content class=toc-link aria-label="Back To Top" title=top><button class="mdui-fab mdui-ripple"><i class="nexmoefont icon-caret-top"></i></button></a></div></div></div></div></div><div id=nexmoe-search-space><div class=search-container><div class=search-header><div class=search-input-container><input class=search-input type=text placeholder=搜索 oninput=sinput()></div><a class=search-close onclick=sclose()>×</a></div><div class=search-body></div></div></div><script src=/lib/mdui_043tiny/mdui.js></script><script src=/lib/fancybox/fancybox.umd.js></script><script async src="/js/app.js?v=1674748240656"></script><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-2058306854838448" crossorigin=anonymous></script></body></html>